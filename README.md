# Banana Quality Assessment System (BananaScan)

## Project Overview
BananaScan is a deep learning system that automatically classifies banana ripeness and predicts a Freshness Index (0–10) from RGB images.  
It integrates image preprocessing, classification, regression, and database logging to assess quality, detect defects, and estimate shelf life.

**Goal:** Automate banana ripeness evaluation and freshness prediction using computer vision.  
**Tech Stack:** Python, TensorFlow/Keras, OpenCV, Pandas, Streamlit, SQLite  
**Model:** MobileNetV2 (pretrained on ImageNet) fine-tuned for 6 ripeness classes  
**Outputs:** Ripeness class prediction and Freshness Index regression  

---

## Repository Structure

banana_dataset/ # Dataset (train, valid, test)
├── train/ # Training images and _classes.csv
├── valid/ # Validation images and _classes.csv
├── test/ # Test images and _classes.csv
├── train_processed/ # Generated by preprocessing
├── valid_processed/
├── test_processed/
├── models/
│ ├── banana_quality_model.keras
│ └── banana_quality.weights.h5
└── produce_quality.db # SQLite database

common_config.py # Global configuration file
preprocess_images.py # Image preprocessing script
train_mobilenetv2.py # Model training pipeline
evaluate_and_db.py # Evaluation and SQLite integration
streamlit_app.py # Interactive Streamlit dashboard
requirements.txt # Python dependencie


---

## Dataset and Preprocessing

**Dataset Overview:**
- Total images: **15,794 (train)**, **1,527 (validation)**, **759 (test)**
- Classes: `freshripe`, `freshunripe`, `overripe`, `ripe`, `rotten`, `unripe`
- Images captured under varying lighting conditions and backgrounds.

### Preprocessing Pipeline (`preprocess_images.py`)

| Step | Description |
|------|--------------|
| Brightness Adjustment | Automatically corrects exposure using gamma correction |
| Color Segmentation | HSV-based masking to isolate banana pixels |
| Smart Mask Refinement | Morphological operations (open/close) and Gaussian blur to smooth edges |
| Background Blending | Applies smooth alpha blending with blurred or averaged backgrounds |
| CLAHE | Enhances contrast in LAB color space without losing natural tones |
| Denoising | Removes minor noise using FastNlMeansDenoisingColored |
| Resize | Resizes all images to 224×224 |
| Augmentation | Random flips, rotations, zoom, and light color variations (for training only) |

This pipeline creates visually consistent, color-balanced images while preserving natural texture and brown-spot detail, improving classification robustness under real-world lighting.

---

## Model Architecture (`train_mobilenetv2.py`)

| Component | Details |
|------------|----------|
| **Base Model** | MobileNetV2 (pretrained on ImageNet) |
| **Input Size** | 224×224×3 |
| **Classification Head** | Dense layer with 6 softmax units (`class_output`) |
| **Regression Head** | Dense layer with 1 sigmoid unit scaled to [0–10] (`freshness_output`) |
| **Loss Function** | Weighted categorical crossentropy + Mean Squared Error (MSE) |
| **Optimizer** | Adam (learning rate = 1e-4) |
| **Training Phases** | Warmup (5 epochs, frozen base) + Fine-tuning (5 epochs, last 60 layers unfrozen) |

### Training Configuration
- **Batch Size:** 32  
- **Seed:** 42  
- **Learning Rate Schedule:** Warmup + ReduceLROnPlateau  
- **Class Balancing:** Dynamic weights computed from label distribution  
- **Loss Weights:** `{ "class_output": 1.0, "freshness_output": 0.1 }`

### Training Process
1. **Warmup Phase:**  
   - Train only the classifier/regressor heads while freezing the MobileNetV2 base.
2. **Fine-Tuning Phase:**  
   - Unfreeze the last 60 layers for banana-specific texture learning.
3. **Checkpointing:**  
   - Saves best weights to `banana_quality.weights.h5`
4. **Final Model:**  
   - Combined and exported as `banana_quality_model.keras`

---

## Model Performance Summary

| Metric | Result | Interpretation |
|---------|---------|----------------|
| **Classification Accuracy** | ~59% | Moderate performance for a 6-class classification task |
| **AUC (Area Under Curve)** | **0.91** | Excellent separability between ripeness stages |
| **Precision** | ~0.69 | Indicates relatively few false positives |
| **Recall** | ~0.50 | Needs improvement (data imbalance / underrepresented classes) |
| **Freshness MAE** | **1.65 / 10** | Low prediction error for regression task |

**Summary:**  
Despite diverse lighting and complex visual conditions, the model achieves strong discriminative power (AUC > 0.9) and a stable regression head.  
Future improvement can focus on recall through dataset rebalancing and extended fine-tuning.

---

## Evaluation and Database Integration (`evaluate_and_db.py`)

This module evaluates the trained model on the test dataset and stores predictions into a local SQLite database.

**Steps:**
1. Load trained model (`.keras`) with custom loss definitions.
2. Load test images (processed if available).
3. Perform inference and generate:
   - Predicted class
   - Confidence score
   - Freshness Index
4. Compute metrics (Accuracy, Precision, Recall, F1-score).
5. Insert results into SQLite across three tables:
   - `Produce_Samples`: metadata and file hash
   - `Quality_Results`: classification output
   - `Shelf_Life_Metrics`: estimated storage days and decay rate

**Database Schema:**

| Table | Description |
|--------|-------------|
| Produce_Samples | Image info, hash, timestamp |
| Quality_Results | Class prediction + confidence + freshness index |
| Shelf_Life_Metrics | Derived shelf-life estimation (days, temperature) |

**Run Evaluation:**
```bash
python evaluate_and_db.py
